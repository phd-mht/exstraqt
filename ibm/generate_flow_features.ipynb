{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "662e1c3f-8825-429c-857b-bcfc0c1545d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "\n",
    "from pyspark.sql import types as st\n",
    "from pyspark.sql.window import Window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3993fd76-dd22-45a9-aefd-e37e2292758f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FLOWS_LOCATION = f\"{location_main}{os.sep}flows_intermediate{os.sep}\"\n",
    "shutil.rmtree(FLOWS_LOCATION, ignore_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff7e82-f37a-4d5a-902a-e033287a7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_and_load_intermediate_data(data_to_load):\n",
    "    location_intermediate = f\"{FLOWS_LOCATION}{uuid.uuid4()}\"\n",
    "    data_to_load.write.parquet(location_intermediate, mode=\"overwrite\")\n",
    "    return spark.read.parquet(location_intermediate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "945d95e6-ad47-4c78-9da3-4387ea8610cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_agg = (\n",
    "    data_input.groupby([\"source\", \"target\"])\n",
    "    .agg(\n",
    "        sf.sum(\"amount\").alias(\"amount\")\n",
    "    )\n",
    ").repartition(os.cpu_count(), \"source\", \"target\")\n",
    "data_agg = save_and_load_intermediate_data(data_agg)\n",
    "# print(\"data_agg\", data_agg.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b0b0ed-bb7c-46ea-aff8-542335fe9e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "totals_sent = data_agg.groupby(\"source\").agg(\n",
    "    sf.sum(\"amount\").alias(\"amount\")\n",
    ").toPandas().set_index(\"source\")[\"amount\"].to_dict()\n",
    "totals_received = data_agg.groupby(\"target\").agg(\n",
    "    sf.sum(\"amount\").alias(\"amount\")\n",
    ").toPandas().set_index(\"target\")[\"amount\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7c627-1d78-4c2b-be10-934c35c05710",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_communities(top_n, n_hops, data_input, pov, cp, totals, to_check_in):\n",
    "    if not(0 < n_hops < 11):\n",
    "        raise NotImplementedError\n",
    "    if top_n < 1:\n",
    "        raise ValueError\n",
    "    \n",
    "    to_check_in = pd.DataFrame(to_check_in, columns=[\"match_with\"])\n",
    "    to_check_in.loc[:, \"total\"] = to_check_in[\"match_with\"].apply(lambda x: totals[x])\n",
    "    to_check_in.to_parquet(f\"{FLOWS_LOCATION}to_check_in.parquet\")\n",
    "    to_check_in = spark.read.parquet(\n",
    "        f\"{FLOWS_LOCATION}to_check_in.parquet\"\n",
    "    ).repartition(os.cpu_count(), \"match_with\")\n",
    "    to_check_in = save_and_load_intermediate_data(to_check_in)\n",
    "\n",
    "    data_input = data_input.where(sf.col(\"source\") != sf.col(\"target\")).join(\n",
    "        to_check_in,\n",
    "        sf.col(pov) == sf.col(\"match_with\"), how=\"inner\"\n",
    "    ).drop(\"match_with\").repartition(os.cpu_count(), pov)\n",
    "    data_input = save_and_load_intermediate_data(data_input)\n",
    "    \n",
    "    window = Window.partitionBy(sf.col(pov)).orderBy(sf.col(\"amount\").desc())\n",
    "    \n",
    "    level_1st = data_input.select(\n",
    "        \"*\", sf.row_number().over(window).alias(\"row_number\")\n",
    "    ).where(sf.col(\"row_number\") <= top_n).drop(\"row_number\")\n",
    "    level_1st = level_1st.withColumn(\n",
    "        \"amount\", sf.least(\"amount\", \"total\")\n",
    "    ).drop(\"total\").repartition(os.cpu_count(), \"source\")\n",
    "    level_1st = save_and_load_intermediate_data(level_1st)\n",
    "\n",
    "    level_1st_comms = level_1st.groupby(pov).agg(\n",
    "        sf.collect_list(cp).alias(\"nodes\"), sf.collect_list(\"amount\").alias(\"amounts\")\n",
    "    )\n",
    "    level_1st_comms = save_and_load_intermediate_data(level_1st_comms)\n",
    "\n",
    "    # print(f\"Processed hop #1 | {level_1st.count():,} | {level_1st_comms.count():,}\")\n",
    "\n",
    "    result = [level_1st_comms.select(\"*\").alias(\"hop_1\")]\n",
    "    for n_hop in range(1, n_hops):\n",
    "        if n_hop == 1:\n",
    "            n_minus_1 = level_1st.select(\"*\").alias(f\"hop_{n_hop + 1}\")\n",
    "        else:\n",
    "            n_minus_1 = level_nth.select(\"*\").alias(f\"hop_{n_hop + 1}\")\n",
    "        for column in n_minus_1.columns:\n",
    "            n_minus_1 = n_minus_1.withColumnRenamed(column, f\"{column}_left\")\n",
    "        level_nth = n_minus_1.join(\n",
    "            level_1st, sf.col(\"target_left\") == sf.col(\"source\"), how=\"inner\"\n",
    "        ).select(\n",
    "            sf.col(\"source_left\").alias(\"source\"), \"target\", \n",
    "            sf.least(\"amount_left\", \"amount\").alias(\"amount\")\n",
    "        ).where(sf.col(\"source\") != sf.col(\"target\")).repartition(\n",
    "            os.cpu_count(), \"source\", \"target\"\n",
    "        )\n",
    "        level_nth = save_and_load_intermediate_data(level_nth)\n",
    "    \n",
    "        level_nth = level_nth.groupby([\"source\", \"target\"]).agg(\n",
    "            sf.sum(\"amount\").alias(\"amount\")\n",
    "        ).repartition(\n",
    "            os.cpu_count(), pov\n",
    "        )\n",
    "        level_nth = save_and_load_intermediate_data(level_nth)\n",
    "            \n",
    "        level_nth = level_nth.join(\n",
    "            to_check_in,\n",
    "            sf.col(pov) == sf.col(\"match_with\"), how=\"inner\"\n",
    "        ).drop(\"match_with\").repartition(\n",
    "            os.cpu_count(), pov\n",
    "        )\n",
    "        level_nth = save_and_load_intermediate_data(level_nth)\n",
    "        \n",
    "        level_nth = level_nth.select(\n",
    "            \"*\", sf.row_number().over(window).alias(\"row_number\")\n",
    "        ).where(sf.col(\"row_number\") <= top_n).drop(\"row_number\").withColumn(\n",
    "            \"amount\", sf.least(\"amount\", \"total\")\n",
    "        ).drop(\"total\").repartition(\n",
    "            os.cpu_count(), \"target\"\n",
    "        )\n",
    "        level_nth = save_and_load_intermediate_data(level_nth)\n",
    "\n",
    "        level_nth_comms = level_nth.groupby(pov).agg(\n",
    "            sf.collect_list(cp).alias(\"nodes\"), sf.collect_list(\"amount\").alias(\"amounts\")\n",
    "        )\n",
    "        level_nth_comms = save_and_load_intermediate_data(level_nth_comms)\n",
    "        \n",
    "        # print(f\"Processed hop #{n_hop + 1} | {level_nth.count():,} | {level_nth_comms.count():,}\")\n",
    "\n",
    "        result.append(level_nth_comms.select(\"*\").alias(f\"hop_{n_hop + 1}\"))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79042103-158e-47bc-98e6-00fa01168f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_flows = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153c715-8699-4abf-9e1b-99949d37bc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nProcessing comm_as_source\\n\")\n",
    "comm_as_source = get_communities(\n",
    "    TOP_N, NUM_HOPS, data_agg, \"source\", \"target\", \n",
    "    totals_sent, nodes_source\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd484ee-cf34-466c-980c-f1d4978a57e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nProcessing comm_as_target\\n\")\n",
    "comm_as_target = get_communities(\n",
    "    TOP_N, NUM_HOPS, data_agg, \"target\", \"source\", \n",
    "    totals_received, nodes_target\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177aeb50-c10d-47d9-86c1-8d33ace73688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nProcessing comm_as_passthrough\\n\")\n",
    "comm_as_passthrough = get_communities(\n",
    "    TOP_N, NUM_HOPS, data_agg, \"source\", \"target\", \n",
    "    totals_received, nodes_passthrough\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb39d7f-832b-4baa-9e18-ffc2b0863430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"\\nProcessing comm_as_passthrough_reverse\\n\")\n",
    "comm_as_passthrough_reverse = get_communities(\n",
    "    TOP_N, NUM_HOPS, data_agg, \"target\", \"source\", \n",
    "    totals_sent, nodes_passthrough\n",
    ")\n",
    "# print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea53bdeb-060f-4572-88c9-5e1a24f238f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_array(array):\n",
    "    return float(np.std(array))\n",
    "\n",
    "def max_array(array):\n",
    "    return max(array)\n",
    "\n",
    "std_array = sf.udf(std_array, st.FloatType())\n",
    "max_array = sf.udf(max_array, st.FloatType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cab5ee-f605-4b76-bf4c-95450c98d39c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_global_features(input_data, pov, totals):\n",
    "    result = pd.DataFrame(totals.items(), columns=[pov, \"total\"])\n",
    "    for index, hop_data in enumerate(input_data):\n",
    "        index += 1\n",
    "        flows_nth = hop_data.select(\n",
    "            pov, \n",
    "            sf.aggregate(\"amounts\", sf.lit(0.0), operator.add).alias(f\"flow_hop_{index}_total\"),\n",
    "            sf.size(\"nodes\").alias(f\"flow_hop_{index}_number_of_nodes\"),\n",
    "            std_array(\"amounts\").alias(f\"flow_hop_{index}_std_amounts\"),\n",
    "            max_array(\"amounts\").alias(f\"flow_hop_{index}_max_amounts\"),\n",
    "        ).toPandas()\n",
    "        result = result.set_index(pov).join(\n",
    "            flows_nth.set_index(pov), how=\"left\"\n",
    "        ).reset_index()\n",
    "        result.loc[:, f\"flow_hop_{index}_rel_transferred\"] = (\n",
    "            result.loc[:, f\"flow_hop_{index}_total\"] / result.loc[:, \"total\"]\n",
    "        )\n",
    "    return result.rename(columns={pov: \"key\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ed78fd-8a2a-41bd-8908-b73835a59247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# print(\"\\ncomm_as_source_features\\n\")\n",
    "comm_as_source_features = construct_global_features(comm_as_source, \"source\", totals_sent)\n",
    "del comm_as_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec56cd2-0b7f-42b5-a2da-a1a29178cd24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# print(\"\\ncomm_as_target_features\\n\")\n",
    "comm_as_target_features = construct_global_features(comm_as_target, \"target\", totals_received)\n",
    "del comm_as_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb95904-1c97-4442-9400-82f4980a4c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# print(\"\\ncomm_as_passthrough_features\\n\")\n",
    "comm_as_passthrough_features = construct_global_features(\n",
    "    comm_as_passthrough, \"source\", totals_received\n",
    ")\n",
    "del comm_as_passthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28a12aec-2369-442b-b1c8-37bff8f90cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# print(\"\\ncomm_as_passthrough_features_reverse\\n\")\n",
    "comm_as_passthrough_features_reverse = construct_global_features(\n",
    "    comm_as_passthrough_reverse, \"target\", totals_sent\n",
    ")\n",
    "del comm_as_passthrough_reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0be459-fb3f-4227-8f88-2fe5fb56a5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"FLOWS ET: {round(time.time() - st_flows)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2836cd53-b001-481c-ae52-103e5b798531",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\")\n",
    "comm_as_source_features.set_index(\"key\", inplace=True)\n",
    "comm_as_target_features.set_index(\"key\", inplace=True)\n",
    "comm_as_passthrough_features.set_index(\"key\", inplace=True)\n",
    "comm_as_passthrough_features_reverse.set_index(\"key\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd680f8-553d-4dbd-ad42-959b6b2d3fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_as_source_features.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in comm_as_source_features.columns]\n",
    "comm_as_target_features.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in comm_as_target_features.columns]\n",
    "comm_as_passthrough_features.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in comm_as_passthrough_features.columns]\n",
    "comm_as_passthrough_features_reverse.columns = [f\"{s.G_GLOB_PREFIX}{x}\" for x in comm_as_passthrough_features_reverse.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bea3280-0503-45db-af06-975c0f80ddd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.rmtree(FLOWS_LOCATION, ignore_errors=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
