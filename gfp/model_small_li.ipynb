{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Copyright 2024 IBM Corporation\n",
    "\n",
    "Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "you may not use this file except in compliance with the License.\n",
    "You may obtain a copy of the License at\n",
    "\n",
    "     http://www.apache.org/licenses/LICENSE-2.0\n",
    "\n",
    "Unless required by applicable law or agreed to in writing, software\n",
    "distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "See the License for the specific language governing permissions and\n",
    "limitations under the License.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training LightGBM model for AML using graph features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snapml import GraphFeaturePreprocessor\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_data_path = \"./aml-demo-data/out_dir_small_li/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6924049 1384810\n"
     ]
    }
   ],
   "source": [
    "total_size = pd.read_csv(f\"{formatted_data_path}formatted_transactions.csv\").shape[0]\n",
    "n_test = round(total_size * 0.2)\n",
    "print(total_size, n_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the input transacton file enriched with graph-based features.\n",
    "transactions_path = formatted_data_path + \"formatted_transactions.csv\"\n",
    "\n",
    "# Set the column indices to be removed: Transaction ID, Source Account ID, Target Account ID, Source Bank ID, Target Bank ID\n",
    "remove_cols = [0,1,2,10,11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading test data\n",
      "Data loaded succesfully.\n",
      "Data shape is  (6924049, 18)\n"
     ]
    }
   ],
   "source": [
    "print(\"Loading test data\")\n",
    "X_all = np.loadtxt(transactions_path, dtype=np.float64, delimiter=\",\", comments=\"#\", skiprows=1)\n",
    "\n",
    "Y_all = X_all[:,-1] # Labels\n",
    "X_all = X_all[:,:-1] # Drop labels\n",
    "\n",
    "print(\"Data loaded succesfully.\")\n",
    "print(\"Data shape is \", X_all.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating a graph feature preprocessor \n",
      "Setting the parameters of the graph feature preprocessor \n"
     ]
    }
   ],
   "source": [
    "print(\"Creating a graph feature preprocessor \")\n",
    "gp = GraphFeaturePreprocessor()\n",
    "\n",
    "print(\"Setting the parameters of the graph feature preprocessor \")\n",
    "tw_days = 1\n",
    "gf_params = {\n",
    "    # Number of software threads to be used\n",
    "    \"num_threads\": 12,\n",
    "\n",
    "    # Enable account statistics\n",
    "    \"vertex_stats\": True,\n",
    "    \"vertex_stats_cols\": [3,6],\n",
    "\n",
    "    # Enable graph-pattern-based features\n",
    "    \"fan\": True,\n",
    "    \"degree\": True,\n",
    "    \"scatter-gather\": True,\n",
    "    \"temp-cycle\": True,\n",
    "    \"lc-cycle\": True,\n",
    "    \"lc-cycle_len\": 10,\n",
    "\n",
    "    # Set time window parameters\n",
    "    \"time_window\": tw_days*24*3600,\n",
    "    \"vertex_stats_tw\": tw_days*24*3600,\n",
    "    \"scatter-gather_tw\": 6*3600,\n",
    "    \"temp-cycle_tw\": tw_days*24*3600,\n",
    "    \"lc-cycle_tw\": tw_days*24*3600,\n",
    "}\n",
    "gp.set_params(gf_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "params 23\n",
      "sub_params 151\n"
     ]
    }
   ],
   "source": [
    "print(\"params\", len(gp.get_params().keys()))\n",
    "print(\"sub_params\", sum([len(x) if isinstance(x, list) else 1 for x in gp.get_params().values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function for determining the number of graph-based features produced by Graph Feature Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_num_gf_feats(gf):\n",
    "    params = gf.get_params()\n",
    "    feat_num = 0\n",
    "\n",
    "    # add features names for the graph patterns\n",
    "    for pattern in [\"fan\", \"degree\", \"scatter-gather\", \"temp-cycle\", \"lc-cycle\"]:\n",
    "        if pattern in params:\n",
    "            if params[pattern]:\n",
    "                bins = len(params[pattern +\"_bins\"])\n",
    "                if pattern in [\"fan\", \"degree\"]:\n",
    "                    feat_num += 2*bins\n",
    "                else:\n",
    "                    feat_num += bins\n",
    "\n",
    "    # add fan, deg, and ratio features\n",
    "    for k in [0, 1, 2]:\n",
    "        if k in params[\"vertex_stats_feats\"]:\n",
    "            feat_num += 4\n",
    "\n",
    "    # add avg, sum, min, max, median, var, skew, and kurtosis features\n",
    "    for k in [3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "        if k in params[\"vertex_stats_feats\"]:\n",
    "            feat_num += 4*len(params[\"vertex_stats_cols\"])\n",
    "\n",
    "    return feat_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate graph-based features using Graph Feature Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3h 24min 47s, sys: 37.6 s, total: 3h 25min 24s\n",
      "Wall time: 21min 26s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "X_all_gf = gp.transform(X_all.astype(np.float64)).astype(np.float32, copy=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data to train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all_gf = np.delete(X_all_gf, remove_cols, 1)\n",
    "\n",
    "X_train_gf = X_all_gf[:-n_test]\n",
    "X_test_gf = X_all_gf[-n_test:]\n",
    "del X_all_gf\n",
    "\n",
    "# Labels\n",
    "y_train = Y_all[:-n_test]\n",
    "y_test = Y_all[-n_test:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5539239, 248), (1384810, 248))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_gf.shape, X_test_gf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM Model Training\n",
    "\n",
    "### Function for training LightGBM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_train_evaluate(X_train, y_train, X_test, y_test, params):\n",
    "        \"\"\" Evaluate an LightGBM configuration\n",
    "\n",
    "        Args:\n",
    "            X_train (np.ndarray): Training feature matrix\n",
    "            y_train (np.ndarray): Training labels\n",
    "            X_test (np.ndarray): Test feature matrix\n",
    "            y_test (np.ndarray): Test labels\n",
    "            params (dict): Model configuration\n",
    "\n",
    "        Returns:\n",
    "            score (float): Configuration score\n",
    "        \"\"\"\n",
    "\n",
    "        lgb_params = params.copy()\n",
    "        num_round = lgb_params[\"num_round\"]\n",
    "        lgb_params.pop(\"num_round\")\n",
    "\n",
    "        lgb_params[\"objective\"] = \"binary\"\n",
    "        lgb_params.pop(\"alpha\")\n",
    "        lgb_params.pop(\"gamma\")\n",
    "\n",
    "        early_stopping_rounds = 20\n",
    "        dtrain = lgb.Dataset(X_train, y_train, weight=None)\n",
    "        dtest = lgb.Dataset(X_test, y_test, weight=None)\n",
    "\n",
    "        bst = lgb.train(\n",
    "            lgb_params,\n",
    "            dtrain,\n",
    "            num_boost_round=num_round,\n",
    "            valid_sets=[dtest],\n",
    "            callbacks=[lgb.early_stopping(stopping_rounds=early_stopping_rounds), lgb.log_evaluation(50)]\n",
    "        )\n",
    "\n",
    "        z_test = bst.predict(X_test)\n",
    "        preds = np.round(z_test)  # 1: illicit, 0: licit\n",
    "\n",
    "        return f1_score(y_test, preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model with graph-based features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training using graph-based features.\n",
      "==================================================\n",
      "[LightGBM] [Info] Number of positive: 2640, number of negative: 5536599\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.531293 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 14935\n",
      "[LightGBM] [Info] Number of data points in the train set: 5539239, number of used features: 185\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.000477 -> initscore=-7.648357\n",
      "[LightGBM] [Info] Start training from score -7.648357\n",
      "Training until validation scores don't improve for 20 rounds\n",
      "[50]\tvalid_0's auc: 0.975395\n",
      "[100]\tvalid_0's auc: 0.977004\n",
      "[150]\tvalid_0's auc: 0.977188\n",
      "Early stopping, best iteration is:\n",
      "[132]\tvalid_0's auc: 0.977331\n",
      "==================================================\n",
      "Test minority-class F1 score:  0.2573940847322142\n"
     ]
    }
   ],
   "source": [
    "# Set the training parameters. These parameters can be found using a Hyperparameter Tuning method such as Successive Halving.\n",
    "params = {\n",
    "    \"boosting\": \"gbdt\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"num_round\": 185,\n",
    "    \"num_leaves\": 21,\n",
    "    \"max_bin\": 256,\n",
    "    \"learning_rate\": 0.08995441299910924,\n",
    "    \"lambda_l1\": 0.4902016501409548,\n",
    "    \"lambda_l2\": 81.93169246795033,\n",
    "    \"scale_pos_weight\": 4.495921090533586,\n",
    "    \"alpha\": 0.8028096762102561,\n",
    "    \"gamma\": 2.1902844884226473,\n",
    "    \"seed\": 5935727,\n",
    "    \"max_depth\": 10\n",
    "}\n",
    "\n",
    "print(\"Training using graph-based features.\")\n",
    "print(\"=\" * 50)\n",
    "res_score = lgbm_train_evaluate(X_train_gf, y_train, X_test_gf, y_test, params)\n",
    "print(\"=\" * 50)\n",
    "print(\"Test minority-class F1 score: \", res_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25.74\n"
     ]
    }
   ],
   "source": [
    "print(round(res_score * 100, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
